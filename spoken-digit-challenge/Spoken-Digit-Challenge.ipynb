{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spoken Digit Challenge\n",
    "This is the first challenge of our Speech and Machine Learning Workshop. Here we will use the [FSDD][] Free Spoken Digit Dataset to build different models and recognize the digits from speech.   \n",
    "\n",
    "** Note: ** Make sure that your dataset is in the correct folder - if there´s something not working for you, feel free to ask.\n",
    "\n",
    "* 1500 recordings in total (150 per digit)\n",
    "* 8kHz sampling rate\n",
    "* 3 speakers\n",
    "* English \n",
    "* File format: {digit\\_label}\\_{speaker\\_name}\\_{index}.wav <br> (e.g. \"4\\_jackson\\_16.wav\")\n",
    "\n",
    "[FSDD]: https://github.com/Jakobovski/free-spoken-digit-dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the relevant modules to be used later\n",
    "import glob\n",
    "import os\n",
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "\n",
    "\n",
    "\n",
    "# Config matplotlib for inline plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset directory\n",
    "DATASET_DIR = \"dataset/\"\n",
    "\n",
    "# Create a list of all .wav files in the dataset directoy paths \n",
    "sound_paths = [DATASET_DIR + f for f in os.listdir(DATASET_DIR) if f[-4:] == '.wav' and 'jackson' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_sound_files(file_paths):\n",
    "    return [librosa.load(fp)[0] for fp in file_paths]\n",
    "\n",
    "def plot_wave(sound_name_with_raw_data):\n",
    "    i = 1\n",
    "    plt.figure(figsize=(15, 2 * len(sound_name_with_raw_data) if len(sound_name_with_raw_data) > 1 else 4))\n",
    "    for n,d in sound_name_with_raw_data:\n",
    "        plt.subplot(np.ceil(float(len(sound_name_with_raw_data))/2), 2, i)\n",
    "        \n",
    "        # wave plot\n",
    "        librosa.display.waveplot(np.array(d),sr=8000)\n",
    "        \n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.title(n)\n",
    "        i += 1\n",
    "    plt.subplots_adjust(top=0.8, bottom=0.08, left=0.10, right=0.95, hspace=0.5, wspace=0.35)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_spectrogram(sound_name_with_raw_data):\n",
    "    i = 1\n",
    "    plt.figure(figsize=(15, 2 * len(sound_name_with_raw_data) if len(sound_name_with_raw_data) > 1 else 4))\n",
    "    for n,d in sound_name_with_raw_data:\n",
    "        plt.subplot(np.ceil(float(len(sound_name_with_raw_data))/2), 2, i)\n",
    "        \n",
    "        # Spectrogram\n",
    "        specgram(np.array(d), Fs=8000, NFFT=512, noverlap=248, scale=\"dB\", vmax=20)\n",
    "        \n",
    "        plt.title(n)\n",
    "        i += 1\n",
    "    plt.subplots_adjust(top=0.8, bottom=0.08, left=0.10, right=0.95, hspace=0.5, wspace=0.35)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Target sound filenames for visualization\n",
    "sound_filenames = [str(i) + '_jackson_0.wav' for i in range(0, 10)]\n",
    "\n",
    "# Load sound files used in visualization\n",
    "sound_name_with_raw_data = [(\"Digit \" + os.path.basename(p)[0], librosa.load(p)[0]) for i, p in enumerate(sound_paths) if os.path.basename(p) in sound_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_wave(sound_name_with_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_spectrogram(sound_name_with_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    return mfccs,chroma,mel,contrast,tonnetz\n",
    "\n",
    "def get_features_and_labels(sound_paths):\n",
    "    features, labels = np.empty((0,193)), np.empty(0)\n",
    "    for p in sound_paths:\n",
    "        mfccs, chroma, mel, contrast,tonnetz = extract_feature(p)\n",
    "        ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "        features = np.vstack([features,ext_features])\n",
    "        labels = np.append(labels, int(os.path.basename(p)[0]))\n",
    "    return np.array(features), np.array(labels, dtype = np.int)\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = get_features_and_labels(sound_paths)\n",
    "labels = one_hot_encode(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FEATURE_PATH = 'features/features.txt'\n",
    "LABEL_PATH = 'features/labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(FEATURE_PATH, features, fmt='%10.5f', delimiter='\\t')\n",
    "np.savetxt(LABEL_PATH, labels, fmt='%i', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
