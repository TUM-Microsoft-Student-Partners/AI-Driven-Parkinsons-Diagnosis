{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![msp](https://msdnshared.blob.core.windows.net/media/2016/11/Microsoft_Student_Partner2.jpg)\n",
    "\n",
    "Todos:\n",
    "- Size headings\n",
    "- Random Seed\n",
    "\n",
    "# Spoken Digit Challenge\n",
    "\n",
    "This is the first challenge of our Speech and Machine Learning Workshop. Here we will use the [FSDD][] Free Spoken Digit Dataset to build different models and recognize the digits from speech.   \n",
    "\n",
    "** Note: ** Make sure that your dataset is in the correct folder - if there´s something not working for you, feel free to ask.\n",
    "\n",
    "* 1500 recordings in total (150 per digit)\n",
    "* 8kHz sampling rate\n",
    "* 3 speakers\n",
    "* English \n",
    "* File format: {digit\\_label}\\_{speaker\\_name}\\_{index}.wav <br> (e.g. \"4\\_jackson\\_16.wav\")\n",
    "\n",
    "[FSDD]: https://github.com/Jakobovski/free-spoken-digit-dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Data Import\n",
    "\n",
    "First, we will extract our features from the audio files. Two files will be generated - one for the features and one for the corresponding labels. Each line in our feature-label-pair will represent a single audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the relevant modules to be used later\n",
    "import glob\n",
    "import os\n",
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "\n",
    "# Config matplotlib for inline plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset directory\n",
    "DATASET_DIR = \"dataset/\"\n",
    "\n",
    "# Create a list of all .wav files in the dataset directoy paths\n",
    "single_speaker = True\n",
    "if single_speaker:\n",
    "    sound_paths = [DATASET_DIR + f for f in os.listdir(DATASET_DIR) if f[-4:] == '.wav' and 'jackson' in f]\n",
    "else:\n",
    "    sound_paths = [DATASET_DIR + f for f in os.listdir(DATASET_DIR) if f[-4:] == '.wav']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Let's visualize different sound files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's start with having a look at our data\n",
    "\n",
    "def plot_wave(sound_filenames):\n",
    "    plt.figure(figsize=(15, 2 * len(sound_filenames)))\n",
    "    i = 1\n",
    "    for filename in sound_filenames:\n",
    "        data, sample_rate = librosa.load(DATASET_DIR + filename)\n",
    "        digit_caption = \"Digit \" + os.path.basename(filename)[0]\n",
    "        \n",
    "        plt.subplot(np.ceil(float(len(sound_filenames))/2), 2, i)\n",
    "        librosa.display.waveplot(np.array(data),sr=sample_rate)\n",
    "        i += 1\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.title(digit_caption)\n",
    "    plt.subplots_adjust(top=0.8, bottom=0.08, left=0.10, right=0.95, hspace=0.5, wspace=0.35)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_spectrogram(sound_filenames, spec_type ='MEL'):\n",
    "    i = 1\n",
    "    plt.figure(figsize=(15, 2 * len(sound_filenames)))\n",
    "    for filename in sound_filenames:\n",
    "        data, sample_rate = librosa.load(DATASET_DIR + filename)\n",
    "        digit_caption = \"Digit \" + os.path.basename(filename)[0]\n",
    "        \n",
    "        plt.subplot(np.ceil(float(len(sound_filenames))/2), 2, i)\n",
    "              \n",
    "        if spec_type == 'FFT':\n",
    "            # Plot FFT spectrogram\n",
    "            fft = librosa.stft(data, n_fft=256)\n",
    "            librosa.display.specshow(librosa.amplitude_to_db(fft,ref=np.max),y_axis='log', x_axis='time') \n",
    "        else:\n",
    "            # Plot MEL spectrogram\n",
    "            mel_spectrogram = librosa.feature.melspectrogram(y=data, sr=sample_rate, n_mels=128, fmax=8000)\n",
    "            librosa.display.specshow(librosa.power_to_db(mel_spectrogram,ref=np.max), y_axis='mel', fmax=8000, x_axis='time')\n",
    "\n",
    "        plt.title(digit_caption)\n",
    "        i += 1\n",
    "    plt.subplots_adjust(top=0.8, bottom=0.08, left=0.10, right=0.95, hspace=0.5, wspace=0.35)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Target sound filenames for visualization\n",
    "sound_filenames = [str(i) + '_jackson_0.wav' for i in range(0, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize wave files\n",
    "plot_wave(sound_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot spectogram\n",
    "plot_spectrogram(sound_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "First, we will extract our features from the audio files. Two files will be generated - one for the features and one for the corresponding labels. Each line in our feature-label-pair will represent a single audio file.\n",
    "\n",
    "### MFCC\n",
    "[Mel Frequency Cepstral Coefficients](http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of mel filters we want to extract \n",
    "# A higher number indicates a higher resolution of our signal - however, this\n",
    "# means that we need to train more parameters\n",
    "# 20 - 40 is used in most cases\n",
    "n_mels = 40\n",
    "# The frame size depends on the audio length\n",
    "# For longer samples, the value should be increased\n",
    "frame_size=25\n",
    "\n",
    "def extract_features(file_name):\n",
    "    data, sample_rate = librosa.load(file_name)\n",
    "    melgram = librosa.feature.melspectrogram(data, sr=sample_rate, n_mels=n_mels)\n",
    "    print('Original shape ouf our mel spectrogram data: ' + str(melgram.shape))\n",
    "    \n",
    "    # if our audio is shorter than the frame size, pad with zeroes\n",
    "    if melgram.shape[1] < frame_size:\n",
    "        pad_width = frame_size - melgram.shape[1]\n",
    "        melgram = np.pad(melgram, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        print('Extended shape ouf our mel spectrogram data: ' + str(melgram.shape))\n",
    "    # if it is longer, cut it down\n",
    "    elif melgram.shape[1] > frame_size:\n",
    "        melgram = melgram[:,:frame_size]\n",
    "        print('Cut shape ouf our mel spectrogram data: ' + str(melgram.shape))\n",
    "        \n",
    "    features = np.hstack((melgram))\n",
    "    return features\n",
    "\n",
    "def get_features_and_labels(sound_paths):\n",
    "    features = None\n",
    "    labels = np.empty(0)\n",
    "    for p in sound_paths:\n",
    "        ext_features = extract_features(p)\n",
    "\n",
    "        if features is None:\n",
    "            features = np.empty((0,len(ext_features)))\n",
    "            \n",
    "        features = np.vstack([features,ext_features])\n",
    "        \n",
    "        labels = np.append(labels, int(os.path.basename(p)[0]))\n",
    "    return np.array(features), np.array(labels, dtype = np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = get_features_and_labels(sound_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding:\n",
    "![encoding](https://www.tensorflow.org/images/feature_columns/categorical_column_with_identity.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = one_hot_encode(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FEATURE_PATH = 'features/features.txt'\n",
    "LABEL_PATH = 'features/labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(FEATURE_PATH, features, fmt='%10.5f', delimiter='\\t')\n",
    "np.savetxt(LABEL_PATH, labels, fmt='%i', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classification\n",
    "\n",
    "Now, we will load our generated features and labels in order to train a classifier on it and evaluate its performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.constraints import maxnorm\n",
    "from keras.initializers import lecun_uniform\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, precision_recall_fscore_support)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "Before building the network, we will load the stored data and split the data into three distinct samples: train, test, and eval. \n",
    "![Split Expl](https://image.slidesharecdn.com/dbm630-lecture08-120208003610-phpapp01/95/dbm630-lecture08-11-728.jpg?cb=1328661419)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.loadtxt(FEATURE_PATH)\n",
    "labels = np.loadtxt(LABEL_PATH)\n",
    "\n",
    "print('Label shape: ' + str(labels.shape))\n",
    "feature_dim = features.shape[1]\n",
    "print('Feature dimensions: ' + str(feature_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splits our whole dataset in three parts for training, testing, and evaluating our model\n",
    "def split_train_test_eval (features, labels, train_percentage, test_percentage, eval_percentage):\n",
    "    feature_label_pairs = list(zip(features, labels))\n",
    "    random.shuffle(feature_label_pairs)\n",
    "    #TODO Check Seed\n",
    "    features, labels = zip(*feature_label_pairs)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    sample_size = len(labels)\n",
    "    print('Number of total samples: ' + str(sample_size))\n",
    "    \n",
    "    train_samples = int(sample_size * train_percentage)\n",
    "    test_samples = int(sample_size * test_percentage)\n",
    "    eval_samples = int(sample_size * eval_percentage)\n",
    "    \n",
    "    # just to make sure that we end up with the actual sample size:\n",
    "    if train_samples + test_samples + eval_samples > sample_size:\n",
    "        eval_samples = sample_size - train_samples - test_samples\n",
    "    \n",
    "    print('Train sample size: ' + str(train_samples))\n",
    "    print('Test sample size: ' + str(test_samples))\n",
    "    print('Eval sample size: ' + str(eval_samples))\n",
    "    \n",
    "    train_features = features[0 : train_samples]\n",
    "    train_labels = labels[0 : train_samples]\n",
    "    \n",
    "    test_features = features[train_samples : train_samples + test_samples]\n",
    "    test_labels = labels[train_samples : train_samples + test_samples]\n",
    "    \n",
    "    eval_features = features[train_samples + test_samples : train_samples + test_samples + eval_samples]\n",
    "    eval_labels = labels[train_samples + test_samples : train_samples + test_samples + eval_samples]\n",
    "    \n",
    "    return train_features, train_labels, test_features, test_labels, eval_features, eval_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features, train_labels, test_features, test_labels, eval_features, eval_labels = split_train_test_eval (features, labels, 0.5, 0.3, 0.2)\n",
    "testing = (test_features, test_labels)\n",
    "evaluation = (eval_features, eval_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our first model\n",
    "\n",
    "Let's try it with a DNN with 3 hidden layers\n",
    "![dnn](https://camo.githubusercontent.com/82b7fff72d1c4da37e0c4474bfd0cdd06b1a6a75/687474703a2f2f74656c656772612e70682f66696c652f3137356133343032346263343536353164306265362e706e67)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the network achitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=100, input_dim=feature_dim, activation=\"relu\"))\n",
    "model.add(Dense(units=20,activation=\"relu\"))\n",
    "model.add(Dense(units=20, activation=\"relu\"))\n",
    "model.add(Dense(units=10,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model:\n",
    "1. Define the optimizer\n",
    "2. Compile the the defined model\n",
    "3. Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_features,train_labels, validation_data=evaluation, epochs=20, batch_size=1)\n",
    "\n",
    "\n",
    "\n",
    "MODEL_DIR = \"models/model1.model\"\n",
    "\n",
    "model.save(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_probabilities = np.array(model.predict_proba(test_features))\n",
    "prediction = np.array(model.predict_classes(test_features))\n",
    "                                            \n",
    "test_classes = np.argmax(test_labels, axis=1)\n",
    "print(prediction)\n",
    "print(test_classes)\n",
    "\n",
    "accuracy = accuracy_score(test_classes, prediction)\n",
    "print('Accuracy: ' + str(accuracy))\n",
    "\n",
    "pd.crosstab(test_classes, prediction, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to the presentation\n",
    "Want to learn some more stuff?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next level\n",
    "Lets build a simple LSTM powered network.\n",
    "\n",
    "![lstm](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_features.shape)\n",
    "train_features = train_features.reshape((len(train_features), 1, feature_dim))\n",
    "test_features = test_features.reshape((len(test_features), 1, feature_dim))\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural network with LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(30,return_sequences=True, input_shape=(1, feature_dim)))\n",
    "model.add(LSTM(20))\n",
    "model.add(Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer='adam',\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_features, train_labels, epochs=20, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape for lstm\n",
    "prediction_probabilities = np.array(model.predict_proba(test_features))\n",
    "prediction = np.array(model.predict_classes(test_features))\n",
    "                                            \n",
    "test_classes = np.argmax(test_labels, axis=1)\n",
    "print(prediction)\n",
    "print(test_classes)\n",
    "\n",
    "accuracy = accuracy_score(test_classes, prediction)\n",
    "print('Accuracy: ' + str(accuracy))\n",
    "\n",
    "conf_mat = confusion_matrix(test_classes, prediction)\n",
    "print(conf_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
