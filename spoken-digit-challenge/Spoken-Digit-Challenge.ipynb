{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spoken Digit Challenge\n",
    "\n",
    "This is the first challenge of our Speech and Machine Learning Workshop. Here we will use the [FSDD][] Free Spoken Digit Dataset to build different models and recognize the digits from speech.   \n",
    "\n",
    "** Note: ** Make sure that your dataset is in the correct folder - if there´s something not working for you, feel free to ask.\n",
    "\n",
    "* 1500 recordings in total (150 per digit)\n",
    "* 8kHz sampling rate\n",
    "* 3 speakers\n",
    "* English \n",
    "* File format: {digit\\_label}\\_{speaker\\_name}\\_{index}.wav <br> (e.g. \"4\\_jackson\\_16.wav\")\n",
    "\n",
    "[FSDD]: https://github.com/Jakobovski/free-spoken-digit-dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "First, we will extract our features from the audio files. Two files will be generated - one for the features and one for the corresponding labels. Each line in our feature-label-pair will represent a single audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the relevant modules to be used later\n",
    "import glob\n",
    "import os\n",
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "\n",
    "\n",
    "\n",
    "# Config matplotlib for inline plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset directory\n",
    "DATASET_DIR = \"dataset/\"\n",
    "\n",
    "# Create a list of all .wav files in the dataset directoy paths \n",
    "sound_paths = [DATASET_DIR + f for f in os.listdir(DATASET_DIR) if f[-4:] == '.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_sound_files(file_paths):\n",
    "    return [librosa.load(fp)[0] for fp in file_paths]\n",
    "\n",
    "def plot_wave(sound_name_with_raw_data):\n",
    "    i = 1\n",
    "    plt.figure(figsize=(15, 2 * len(sound_name_with_raw_data) if len(sound_name_with_raw_data) > 1 else 4))\n",
    "    for n,d in sound_name_with_raw_data:\n",
    "        plt.subplot(np.ceil(float(len(sound_name_with_raw_data))/2), 2, i)\n",
    "        \n",
    "        # wave plot\n",
    "        librosa.display.waveplot(np.array(d),sr=8000)\n",
    "        \n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.title(n)\n",
    "        i += 1\n",
    "    plt.subplots_adjust(top=0.8, bottom=0.08, left=0.10, right=0.95, hspace=0.5, wspace=0.35)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_spectrogram(sound_name_with_raw_data):\n",
    "    i = 1\n",
    "    plt.figure(figsize=(15, 2 * len(sound_name_with_raw_data) if len(sound_name_with_raw_data) > 1 else 4))\n",
    "    for n,d in sound_name_with_raw_data:\n",
    "        plt.subplot(np.ceil(float(len(sound_name_with_raw_data))/2), 2, i)\n",
    "        \n",
    "        # Spectrogram\n",
    "        specgram(np.array(d), Fs=8000, NFFT=512, noverlap=248, scale=\"dB\", vmax=20)\n",
    "        \n",
    "        plt.title(n)\n",
    "        i += 1\n",
    "    plt.subplots_adjust(top=0.8, bottom=0.08, left=0.10, right=0.95, hspace=0.5, wspace=0.35)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Target sound filenames for visualization\n",
    "sound_filenames = [str(i) + '_jackson_0.wav' for i in range(0, 10)]\n",
    "\n",
    "# Load sound files used in visualization\n",
    "sound_name_with_raw_data = [(\"Digit \" + os.path.basename(p)[0], librosa.load(p)[0]) for i, p in enumerate(sound_paths) if os.path.basename(p) in sound_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_wave(sound_name_with_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_spectrogram(sound_name_with_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    \n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "\n",
    "    #var = np.var(mfccs, axis=0)\n",
    "    #stddev = np.std(mfccs, axis=0)\n",
    "    #mean = np.mean(mfccs, axis=0)\n",
    "    #mi = mfccs.min(axis=0)\n",
    "    #first_q = np.percentile(mfccs, 25, axis=0)\n",
    "    #median = np.median(mfccs, axis=0)\n",
    "    #third_q = np.percentile(mfccs, 75, axis=0)\n",
    "    #ma = mfccs.max(axis=0)\n",
    "                \n",
    "    #chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    #mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    #contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    #tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "\n",
    "    features = np.hstack((mfccs))\n",
    "    return features\n",
    "\n",
    "def get_features_and_labels(sound_paths):\n",
    "    features = None\n",
    "    labels = np.empty(0)\n",
    "    for p in sound_paths:\n",
    "        ext_features = extract_features(p)\n",
    "\n",
    "        if features is None:\n",
    "            features = np.empty((0,len(ext_features)))\n",
    "            \n",
    "        features = np.vstack([features,ext_features])\n",
    "        \n",
    "        labels = np.append(labels, int(os.path.basename(p)[0]))\n",
    "    return np.array(features), np.array(labels, dtype = np.int)\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode\n",
    "\n",
    "features, labels = get_features_and_labels(sound_paths)\n",
    "labels = one_hot_encode(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FEATURE_PATH = 'features/features.txt'\n",
    "LABEL_PATH = 'features/labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(FEATURE_PATH, features, fmt='%10.5f', delimiter='\\t')\n",
    "np.savetxt(LABEL_PATH, labels, fmt='%i', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classification\n",
    "\n",
    "Now, we will load our generated features and labels in order to train a classifier on it and evaluate its performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.constraints import maxnorm\n",
    "from keras.initializers import lecun_uniform\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, precision_recall_fscore_support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.loadtxt(FEATURE_PATH)\n",
    "labels = np.loadtxt(LABEL_PATH)\n",
    "\n",
    "print('Label shape: ' + str(labels.shape))\n",
    "feature_dim = features.shape[1]\n",
    "print('Feature dimensions: ' + str(feature_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_train_test_eval (features, labels, train_percentage, test_percentage, eval_percentage):\n",
    "    feature_label_pairs = list(zip(features, labels))\n",
    "    random.shuffle(feature_label_pairs)\n",
    "    features, labels = zip(*feature_label_pairs)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    sample_size = len(labels)\n",
    "    print('Number of total samples: ' + str(sample_size))\n",
    "    \n",
    "    train_samples = int(sample_size * train_percentage)\n",
    "    test_samples = int(sample_size * test_percentage)\n",
    "    eval_samples = int(sample_size * eval_percentage)\n",
    "    \n",
    "    # just to make sure that we end up with the actual sample size:\n",
    "    if train_samples + test_samples + eval_samples > sample_size:\n",
    "        eval_samples = sample_size - train_samples - test_samples\n",
    "    \n",
    "    print('Train sample size: ' + str(train_samples))\n",
    "    print('Test sample size: ' + str(test_samples))\n",
    "    print('Eval sample size: ' + str(eval_samples))\n",
    "    \n",
    "    train_features = features[0 : train_samples]\n",
    "    train_labels = labels[0 : train_samples]\n",
    "    \n",
    "    test_features = features[train_samples : train_samples + test_samples]\n",
    "    test_labels = labels[train_samples : train_samples + test_samples]\n",
    "    \n",
    "    eval_features = features[train_samples + test_samples : train_samples + test_samples + eval_samples]\n",
    "    eval_labels = labels[train_samples + test_samples : train_samples + test_samples + eval_samples]\n",
    "    \n",
    "    return train_features, train_labels, test_features, test_labels, eval_features, eval_labels\n",
    "        \n",
    "train_features, train_labels, test_features, test_labels, eval_features, eval_labels = split_train_test_eval (features, labels, 0.5, 0.3, 0.2)\n",
    "    \n",
    "evaluation = (eval_features, eval_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=300, input_dim=feature_dim, activation=\"relu\"))\n",
    "model.add(Dense(units=300,activation=\"relu\"))\n",
    "model.add(Dense(units=50, activation=\"relu\"))\n",
    "model.add(Dense(units=10,activation=\"sigmoid\"))\n",
    "\n",
    "opt = optimizers.SGD(lr=0.001, clipvalue=0.5)\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_features,train_labels, validation_data=evaluation, epochs=100, batch_size=8)\n",
    "\n",
    "MODEL_DIR = \"models/model1.model\"\n",
    "\n",
    "model.save(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_probabilities = np.array(model.predict_proba(test_features))\n",
    "prediction = np.array(model.predict_classes(test_features))\n",
    "                                            \n",
    "test_classes = np.argmax(test_labels, axis=1)\n",
    "print(prediction)\n",
    "print(test_classes)\n",
    "\n",
    "accuracy = accuracy_score(test_classes, prediction)\n",
    "print('Accuracy: ' + str(accuracy))\n",
    "\n",
    "conf_mat = confusion_matrix(test_classes, prediction)\n",
    "print(conf_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
